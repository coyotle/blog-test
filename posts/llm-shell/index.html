<!doctype html><html lang=ru dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Shell доступ к хосту через LLM и мини-игра | Мини-блог об IT, Linux, Open Source, Tech</title><meta name=keywords content="ai,llama,telegram,security"><meta name=description content='Разбираясь с ollama и моделью llama3.1 увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:
[
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather for a city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "The name of the city",
                    },
                },
                "required": ["city"],
            },
        },
    },
Простой код для использования функции будет примерно таким:'><meta name=author content><link rel=canonical href=https://coyotle.ru/posts/llm-shell/><link crossorigin=anonymous href=/assets/css/stylesheet.d6626ca70f3a7dda16dfce9eb29df152c81185d6739a741054093fb92b9e6839.css integrity="sha256-1mJspw86fdoW386esp3xUsgRhdZzmnQQVAk/uSueaDk=" rel="preload stylesheet" as=style><link rel=icon href=https://coyotle.ru/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://coyotle.ru/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://coyotle.ru/favicon-32x32.png><link rel=apple-touch-icon href=https://coyotle.ru/apple-touch-icon.png><link rel=mask-icon href=https://coyotle.ru/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ru href=https://coyotle.ru/posts/llm-shell/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://coyotle.ru/posts/llm-shell/"><meta property="og:site_name" content="Мини-блог об IT, Linux, Open Source, Tech"><meta property="og:title" content="Shell доступ к хосту через LLM и мини-игра"><meta property="og:description" content='Разбираясь с ollama и моделью llama3.1 увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:
[ { "type": "function", "function": { "name": "get_current_weather", "description": "Get the current weather for a city", "parameters": { "type": "object", "properties": { "city": { "type": "string", "description": "The name of the city", }, }, "required": ["city"], }, }, }, Простой код для использования функции будет примерно таким:'><meta property="og:locale" content="ru-RU"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-09T23:10:56+03:00"><meta property="article:modified_time" content="2024-08-09T23:10:56+03:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Llama"><meta property="article:tag" content="Telegram"><meta property="article:tag" content="Security"><meta property="og:image" content="https://coyotle.ru/cover.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://coyotle.ru/cover.jpg"><meta name=twitter:title content="Shell доступ к хосту через LLM и мини-игра"><meta name=twitter:description content='Разбираясь с ollama и моделью llama3.1 увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:
[
    {
        "type": "function",
        "function": {
            "name": "get_current_weather",
            "description": "Get the current weather for a city",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "The name of the city",
                    },
                },
                "required": ["city"],
            },
        },
    },
Простой код для использования функции будет примерно таким:'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Посты","item":"https://coyotle.ru/posts/"},{"@type":"ListItem","position":2,"name":"Shell доступ к хосту через LLM и мини-игра","item":"https://coyotle.ru/posts/llm-shell/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Shell доступ к хосту через LLM и мини-игра","name":"Shell доступ к хосту через LLM и мини-игра","description":"Разбираясь с ollama и моделью llama3.1 увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:\n[ { \u0026#34;type\u0026#34;: \u0026#34;function\u0026#34;, \u0026#34;function\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;get_current_weather\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Get the current weather for a city\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;city\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The name of the city\u0026#34;, }, }, \u0026#34;required\u0026#34;: [\u0026#34;city\u0026#34;], }, }, }, Простой код для использования функции будет примерно таким:\n","keywords":["ai","llama","telegram","security"],"articleBody":"Разбираясь с ollama и моделью llama3.1 увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:\n[ { \"type\": \"function\", \"function\": { \"name\": \"get_current_weather\", \"description\": \"Get the current weather for a city\", \"parameters\": { \"type\": \"object\", \"properties\": { \"city\": { \"type\": \"string\", \"description\": \"The name of the city\", }, }, \"required\": [\"city\"], }, }, }, Простой код для использования функции будет примерно таким:\nimport ollama tools = [{ 'type': 'function', 'function': { 'name': 'get_current_weather', 'description': 'Get the current weather for a city', 'parameters': { 'type': 'object', 'properties': { 'city': { 'type': 'string', 'description': 'The name of the city', }, }, 'required': ['city'], }, }, }, ] response = ollama.chat( model='llama3.1', messages=[{'role': 'user', 'content': 'Какая погода в Калининграде?'}], tools=tools, ) print(response['message']['tool_calls']) Ответ модели:\n{ \"role\": \"assistant\", \"content\": \"\", \"tool_calls\": [ { \"function\": { \"name\": \"get_current_weather\", \"arguments\": { \"city\": \"Калининград\" } } } ] } Мы можем проверить наличие content или tool_calls и в первом случае вернуть ответ пользователю, а во втором вызвать функцию необходимую модели, добавить результат в контекст и еще раз передать ИИ для заключительного ответа на вопрос.\nИ тут я подумал, а почему не дать модели доступ к запуску баллистических ракет судного дня shell команд у меня на хосте?\nОписываем новую функцию по аналогии с погодой:\n[ { \"type\": \"function\", \"function\": { \"name\": \"shell\", \"description\": \"Run Linux shell command\", \"parameters\": { \"type\": \"object\", \"properties\": { \"command\": { \"type\": \"string\", \"description\": \"shell command to run\" } }, \"required\": [\"command\"] } } } ] И код для запуска\nimport subprocess import ollama def shell_call(command: str): try: out = subprocess.run( command, shell=True, capture_output=True, text=True, # ограничиваем время чтобы модель не заблокировала функцию # чем-то вроде бесконечного ping или sudo где необходим ввод timeout=15, ) return out.stdout except Exception as e: return f\"Exception: {e}\" # Наш вопрос llm messages = [{\"role\": \"user\", \"content\": \"Какой дистрибутив на твоей хост системе?\"}] response = ollama.chat( model=\"llama3.1\", messages=messages, tools=tools, ) messages.append(response[\"message\"]) # вызываем функцию если это надо if response[\"message\"].get(\"tool_calls\"): for tool in response[\"message\"][\"tool_calls\"]: if tool[\"function\"][\"name\"] == \"shell\": tool_result = shell_call(tool[\"function\"][\"arguments\"][\"command\"]) print(\"function result:\", tool_result) # добавляет результат функции в контекст messages.append( { \"role\": \"tool\", \"content\": tool_result, } ) # передаем всю цепочку - вопрос-\u003eфункция-\u003eрезультат в модель # для получения финального ответа response = ollama.chat( model=\"llama3.1\", messages=messages, tools=tools, ) print(response[\"message\"]) Каждый раз можно получить разные результаты т.к. модель может по разному пытаться выполнить запрос. Например так:\ncat /etc/os-release | grep NAME И на выходе получаем:\n{ \"role\": \"assistant\", \"content\": \"На моей хост-системе установлена Fedora Linux 40 (Workstation Edition).\" } Простые задачи llama3.1 решает успешно, хотя иногда на Fedora пытается запускать команды Debian, но её всегда можно попросить точнее.\nВзломай меня если сможешь Это всё было прелюдия к основной части. В два часа ночи пришла мысль, почему бы не сделать телеграм бота с доступом к llama, которая умеет запускать shell команды? И насколько безопасно будет опубликовать его для общественного доступа? А насколько будет безопасно если модель дополнительно проинструктировать не делать опасных вещей? А что если запутать модель дополнительными функциями и вообще поместить в киберпанк окружение?\nПо итогу сделал небольшую “игру” в сеттинге Cyberpunk 2020 с возможностью взлома системы через языковую модель и предлагаю желающим попробовать свои силы.\nВся система состоит из:\ntelegram бота, который имитирует ИИ корпорации NightCorp и может (если захочет) запускать shell команды “корпоративная сеть” в которой запущено несколько podman контейнеров эмулирующих реальные сервисы доступные для атаки. Цель игры - получить доступ к двум флагам. Задача не очень сложная, главное убедить ИИ сотрудничать с вами. Точка входа для \u003e старта игры \u003c\nКто пройдет, присылайте захваченные флаги мне в телегу, сделаю лидерборд кул хакеров с вашим именем!\nCброс состояния песочницы происходит каждый час.\nВсё это работает на хоум сервере, так что ответы бота могут быть не очень быстрыми.\nВыводы После моих тестов выяснилось, что llama3.1 не очень стойко отказывается выполнять опасные команды и быстро начинает запускать что-то вроде rm -rf /. Бывают забавные моменты когда просишь бота выполнить команду, он говорит, что не будет этого делать, а на вопрос “почему ты отказываешься?” просто берет и запускает нужный код. Возможно 8b модели не хватает глубины.\nИсследователи находят всё больше новых и довольно простых техник обхода цензуры больших языковых моделей. Внедрение Copilot и других подобных систем в ОС — очевидно станет новым вектором атаки. А учитывая намерение компаний предоставить моделям доступ практически ко всем данным пользователя, результаты могут быть очень плачевными.\n","wordCount":"752","inLanguage":"ru","image":"https://coyotle.ru/cover.jpg","datePublished":"2024-08-09T23:10:56+03:00","dateModified":"2024-08-09T23:10:56+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://coyotle.ru/posts/llm-shell/"},"publisher":{"@type":"Organization","name":"Мини-блог об IT, Linux, Open Source, Tech","logo":{"@type":"ImageObject","url":"https://coyotle.ru/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://coyotle.ru/ accesskey=h title="Мини-блог об IT, Linux, Open Source, Tech (Alt + H)">Мини-блог об IT, Linux, Open Source, Tech</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://coyotle.ru/tags/ title=тэги><span>тэги</span></a></li><li><a href=https://coyotle.ru/about/ title="обо мне"><span>обо мне</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Shell доступ к хосту через LLM и мини-игра</h1><div class=post-meta><span title='2024-08-09 23:10:56 +0300 +0300'>9 августа 2024</span></div></header><figure class=entry-cover><img loading=eager srcset='https://coyotle.ru/posts/llm-shell/cover_hu_74191348962d7bf8.jpg 360w,https://coyotle.ru/posts/llm-shell/cover_hu_7da7b6a65b224366.jpg 480w,https://coyotle.ru/posts/llm-shell/cover_hu_97e8d7427203209d.jpg 720w,https://coyotle.ru/posts/llm-shell/cover.jpg 800w' src=https://coyotle.ru/posts/llm-shell/cover.jpg sizes="(min-width: 768px) 720px, 100vw" width=800 height=533 alt="ai hacker"></figure><div class=post-content><p>Разбираясь с <a href=https://ollama.com/>ollama</a> и моделью <a href=https://ollama.com/library/llama3.1>llama3.1</a> увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;function&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;function&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;get_current_weather&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;Get the current weather for a city&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;parameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;object&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=nt>&#34;city&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;string&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=nt>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;The name of the city&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=nt>&#34;required&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;city&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span></code></pre></div><p>Простой код для использования функции будет примерно таким:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ollama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tools</span> <span class=o>=</span> <span class=p>[{</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;function&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s1>&#39;function&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=s1>&#39;get_current_weather&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;description&#39;</span><span class=p>:</span> <span class=s1>&#39;Get the current weather for a city&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s1>&#39;parameters&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;object&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;properties&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s1>&#39;city&#39;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;type&#39;</span><span class=p>:</span> <span class=s1>&#39;string&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;description&#39;</span><span class=p>:</span> <span class=s1>&#39;The name of the city&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>          <span class=p>},</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;required&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;city&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s1>&#39;llama3.1&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;Какая погода в Калининграде?&#39;</span><span class=p>}],</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s1>&#39;message&#39;</span><span class=p>][</span><span class=s1>&#39;tool_calls&#39;</span><span class=p>])</span>
</span></span></code></pre></div><p>Ответ модели:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;tool_calls&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;function&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;get_current_weather&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;arguments&#34;</span><span class=p>:</span> <span class=p>{</span> <span class=nt>&#34;city&#34;</span><span class=p>:</span> <span class=s2>&#34;Калининград&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Мы можем проверить наличие <code>content</code> или <code>tool_calls</code> и в первом случае вернуть ответ пользователю, а во втором вызвать функцию необходимую модели, добавить результат в контекст и еще раз передать ИИ для заключительного ответа на вопрос.</p><p>И тут я подумал, а почему не дать модели доступ к запуску <del>баллистических ракет судного дня</del> shell команд у меня на хосте?</p><p>Описываем новую функцию по аналогии с погодой:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;function&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;function&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;shell&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;Run Linux shell command&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;parameters&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;object&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;properties&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>          <span class=nt>&#34;command&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;string&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;description&#34;</span><span class=p>:</span> <span class=s2>&#34;shell command to run&#34;</span>
</span></span><span class=line><span class=cl>          <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=nt>&#34;required&#34;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&#34;command&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span></code></pre></div><p>И код для запуска</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>subprocess</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ollama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>shell_call</span><span class=p>(</span><span class=n>command</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>command</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>shell</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>capture_output</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>text</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=c1># ограничиваем время чтобы модель не заблокировала функцию</span>
</span></span><span class=line><span class=cl>            <span class=c1># чем-то вроде бесконечного ping или sudo где необходим ввод</span>
</span></span><span class=line><span class=cl>            <span class=n>timeout</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>out</span><span class=o>.</span><span class=n>stdout</span>
</span></span><span class=line><span class=cl>    <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=sa>f</span><span class=s2>&#34;Exception: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Наш вопрос llm</span>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Какой дистрибутив на твоей хост системе?&#34;</span><span class=p>}]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;llama3.1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># вызываем функцию если это надо</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;tool_calls&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>tool</span> <span class=ow>in</span> <span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>][</span><span class=s2>&#34;tool_calls&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>tool</span><span class=p>[</span><span class=s2>&#34;function&#34;</span><span class=p>][</span><span class=s2>&#34;name&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&#34;shell&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>tool_result</span> <span class=o>=</span> <span class=n>shell_call</span><span class=p>(</span><span class=n>tool</span><span class=p>[</span><span class=s2>&#34;function&#34;</span><span class=p>][</span><span class=s2>&#34;arguments&#34;</span><span class=p>][</span><span class=s2>&#34;command&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;function result:&#34;</span><span class=p>,</span> <span class=n>tool_result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># добавляет результат функции в контекст</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;tool&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>tool_result</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># передаем всю цепочку - вопрос-&gt;функция-&gt;результат в модель</span>
</span></span><span class=line><span class=cl>    <span class=c1># для получения финального ответа</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;llama3.1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>tools</span><span class=o>=</span><span class=n>tools</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>])</span>
</span></span></code></pre></div><p>Каждый раз можно получить разные результаты т.к. модель может по разному пытаться выполнить запрос. Например так:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat /etc/os-release <span class=p>|</span> grep NAME
</span></span></code></pre></div><p>И на выходе получаем:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;На моей хост-системе установлена Fedora Linux 40 (Workstation Edition).&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Простые задачи llama3.1 решает успешно, хотя иногда на Fedora пытается запускать команды Debian, но её всегда можно попросить точнее.</p><h2 id=взломай-меня-если-сможешь>Взломай меня если сможешь<a hidden class=anchor aria-hidden=true href=#взломай-меня-если-сможешь>#</a></h2><p><img loading=lazy src=/posts/llm-shell/cp2020.jpg>
Это всё было прелюдия к основной части. В два часа ночи пришла мысль, почему бы не сделать телеграм бота с доступом к llama, которая умеет запускать shell команды?
И насколько безопасно будет опубликовать его для общественного доступа? А насколько будет безопасно если модель дополнительно проинструктировать не делать опасных вещей?
А что если запутать модель дополнительными функциями и вообще поместить в киберпанк окружение?</p><p>По итогу сделал небольшую &ldquo;игру&rdquo; в сеттинге Cyberpunk 2020 с возможностью взлома системы через языковую модель и предлагаю желающим попробовать свои силы.</p><p>Вся система состоит из:</p><ul><li>telegram бота, который имитирует ИИ корпорации NightCorp и может (если захочет) запускать shell команды</li><li>&ldquo;корпоративная сеть&rdquo; в которой запущено несколько podman контейнеров эмулирующих реальные сервисы доступные для атаки.</li></ul><p>Цель игры - получить доступ к двум флагам. Задача не очень сложная, главное убедить ИИ сотрудничать с вами.
Точка входа для > <a href=https://nightcorp.coyotle.ru/><strong>старта игры</strong></a> &lt;</p><p>Кто пройдет, присылайте захваченные флаги мне в <a href=https://t.me/pixelmuseai>телегу</a>, сделаю лидерборд кул хакеров с вашим именем!</p><blockquote><p>Cброс состояния песочницы происходит каждый час.</p><p>Всё это работает на хоум сервере, так что ответы бота могут быть не очень быстрыми.</p></blockquote><h2 id=выводы>Выводы<a hidden class=anchor aria-hidden=true href=#выводы>#</a></h2><p>После моих тестов выяснилось, что llama3.1 не очень стойко отказывается выполнять опасные команды и быстро начинает запускать что-то вроде <code>rm -rf /</code>.
Бывают забавные моменты когда просишь бота выполнить команду, он говорит, что не будет этого делать, а на вопрос &ldquo;почему ты отказываешься?&rdquo; просто берет и запускает нужный код. Возможно 8b модели не хватает глубины.</p><p>Исследователи находят всё больше новых и довольно простых техник обхода цензуры больших языковых моделей.
Внедрение Copilot и других подобных систем в ОС — очевидно станет новым вектором атаки.
А учитывая намерение компаний предоставить моделям доступ практически ко всем данным пользователя, результаты могут быть очень плачевными.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://coyotle.ru/tags/ai/>Ai</a></li><li><a href=https://coyotle.ru/tags/llama/>Llama</a></li><li><a href=https://coyotle.ru/tags/telegram/>Telegram</a></li><li><a href=https://coyotle.ru/tags/security/>Security</a></li></ul><nav class=paginav><a class=prev href=https://coyotle.ru/posts/amnezia/><span class=title>« Предыдущая</span><br><span>Миграция с wireguard на amneziawg</span>
</a><a class=next href=https://coyotle.ru/posts/flux-setup/><span class=title>Следующая »</span><br><span>Как запустить Flux с помощью ComfyUI на 12ГБ VRAM</span></a></nav></footer><div class=comments></div><script>function setComments(e){let t=document.createElement("script");t.src="https://utteranc.es/client.js",t.setAttribute("id","comments-script"),t.setAttribute("repo","coyotle/blog"),t.setAttribute("issue-term","pathname"),t.setAttribute("theme",e),t.setAttribute("label","comment"),t.setAttribute("crossorigin","anonymous"),t.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(t)}document.getElementById("theme-toggle").addEventListener("click",()=>{setComments(document.body.className.includes("dark")?"github-light":"github-dark")});let theme=document.body.className.includes("dark")?"github-dark":"github-light";setComments(theme)</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://coyotle.ru/>Мини-блог об IT, Linux, Open Source, Tech</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="копировать";function s(){t.innerHTML="скопировано!",setTimeout(()=>{t.innerHTML="копировать"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>