<!doctype html><html lang=ru dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Controlnet для тг-бота pixelmuse | Мини-блог об IT, Linux, Open Source, Tech</title><meta name=keywords content="нейросети,stable diffusion,midjourney,искусство"><meta name=description content="Добавил новую функцию для telegram-бота @pixelmuse_bot. Теперь на вход ему можно отправить кривой рисунок с командой в описании /imagine2 текст запроса и на выходе получить что-то осмысленное и даже красивое.
Как это работает под капотом. Никакой магии, для управления нейросетью используем controlnet. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.
После получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества."><meta name=author content><link rel=canonical href=https://coyotle.ru/posts/pixelmuse-controlnet/><link crossorigin=anonymous href=/assets/css/stylesheet.d6626ca70f3a7dda16dfce9eb29df152c81185d6739a741054093fb92b9e6839.css integrity="sha256-1mJspw86fdoW386esp3xUsgRhdZzmnQQVAk/uSueaDk=" rel="preload stylesheet" as=style><link rel=icon href=https://coyotle.ru/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://coyotle.ru/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://coyotle.ru/favicon-32x32.png><link rel=apple-touch-icon href=https://coyotle.ru/apple-touch-icon.png><link rel=mask-icon href=https://coyotle.ru/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ru href=https://coyotle.ru/posts/pixelmuse-controlnet/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://coyotle.ru/posts/pixelmuse-controlnet/"><meta property="og:site_name" content="Мини-блог об IT, Linux, Open Source, Tech"><meta property="og:title" content="Controlnet для тг-бота pixelmuse"><meta property="og:description" content="Добавил новую функцию для telegram-бота @pixelmuse_bot. Теперь на вход ему можно отправить кривой рисунок с командой в описании /imagine2 текст запроса и на выходе получить что-то осмысленное и даже красивое.
Как это работает под капотом. Никакой магии, для управления нейросетью используем controlnet. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.
После получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества."><meta property="og:locale" content="ru-RU"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-17T20:21:45+03:00"><meta property="article:modified_time" content="2023-10-17T20:21:45+03:00"><meta property="article:tag" content="Нейросети"><meta property="article:tag" content="Stable Diffusion"><meta property="article:tag" content="Midjourney"><meta property="article:tag" content="Искусство"><meta property="og:image" content="https://coyotle.ru/00.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://coyotle.ru/00.jpg"><meta name=twitter:title content="Controlnet для тг-бота pixelmuse"><meta name=twitter:description content="Добавил новую функцию для telegram-бота @pixelmuse_bot. Теперь на вход ему можно отправить кривой рисунок с командой в описании /imagine2 текст запроса и на выходе получить что-то осмысленное и даже красивое.
Как это работает под капотом. Никакой магии, для управления нейросетью используем controlnet. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.
После получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Посты","item":"https://coyotle.ru/posts/"},{"@type":"ListItem","position":2,"name":"Controlnet для тг-бота pixelmuse","item":"https://coyotle.ru/posts/pixelmuse-controlnet/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Controlnet для тг-бота pixelmuse","name":"Controlnet для тг-бота pixelmuse","description":"Добавил новую функцию для telegram-бота @pixelmuse_bot. Теперь на вход ему можно отправить кривой рисунок с командой в описании /imagine2 текст запроса и на выходе получить что-то осмысленное и даже красивое.\nКак это работает под капотом. Никакой магии, для управления нейросетью используем controlnet. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.\nПосле получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества.\n","keywords":["нейросети","stable diffusion","midjourney","искусство"],"articleBody":"Добавил новую функцию для telegram-бота @pixelmuse_bot. Теперь на вход ему можно отправить кривой рисунок с командой в описании /imagine2 текст запроса и на выходе получить что-то осмысленное и даже красивое.\nКак это работает под капотом. Никакой магии, для управления нейросетью используем controlnet. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.\nПосле получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества.\nДля теста нарисовал такой рисунок: Загружаем исходное изображенние с помощью PIL, кропаем и ресайзим до нужного размера:\nimage = Image.open(image_path) image = crop(image) image = image.resize((width, height)) Используем cv2.Canny для создания маски с краями объектов:\nimage = np.array(image) image = cv2.Canny(image, 55, 70) # эти параметры надо продобрать под ваши изображения image = image[:, :, None] image = np.concatenate([image, image, image], axis=2) canny_image = Image.fromarray(image) Получаем что-то такое: В этом проекте я загружаю одну SDXL модель и переиспользую ее для разных задач и комбинаций с LoRa. Загрузка базовой модели происходит из файла safetensors примерно так:\nvae = AutoencoderKL.from_pretrained( \"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16) controlnet = ControlNetModel.from_pretrained( \"diffusers/controlnet-canny-sdxl-1.0\", torch_dtype=torch.float16) pipe = StableDiffusionXLPipeline.from_single_file( model_path, custom_pipeline=\"lpw_stable_diffusion\", max_embeddings_multiples=3, vae=vae, use_safetensors=True, variant=\"fp16\", torch_dtype=torch.float16) pipe.enable_vae_tiling() pipe.enable_xformers_memory_efficient_attention() pipe.scheduler = DPMSolverMultistepScheduler.from_config( pipe.scheduler.config, use_karras_sigmas=True) Затем инициализируем StableDiffusionXLControlNetPipeline с помощью уже загруженной модели и controlnet:\npipe_ctrlnet = StableDiffusionXLControlNetPipeline( **pipe.components, controlnet=controlnet).to('cuda') И генерим изображение:\nimages = pipe_ctrlnet( prompt=prompt, negative_prompt=negative_prompt, image=canny_image, num_inference_steps=20, controlnet_conditioning_scale=0.5, guidance_scale=guidance_scale).images Результат на выходе: ","wordCount":"253","inLanguage":"ru","image":"https://coyotle.ru/00.jpg","datePublished":"2023-10-17T20:21:45+03:00","dateModified":"2023-10-17T20:21:45+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://coyotle.ru/posts/pixelmuse-controlnet/"},"publisher":{"@type":"Organization","name":"Мини-блог об IT, Linux, Open Source, Tech","logo":{"@type":"ImageObject","url":"https://coyotle.ru/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://coyotle.ru/ accesskey=h title="Мини-блог об IT, Linux, Open Source, Tech (Alt + H)">Мини-блог об IT, Linux, Open Source, Tech</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://coyotle.ru/tags/ title=тэги><span>тэги</span></a></li><li><a href=https://coyotle.ru/about/ title="обо мне"><span>обо мне</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Controlnet для тг-бота pixelmuse</h1><div class=post-meta><span title='2023-10-17 20:21:45 +0300 +0300'>17 октября 2023</span></div></header><figure class=entry-cover><img loading=eager srcset='https://coyotle.ru/posts/pixelmuse-controlnet/00_hu_f4a4affe1b1ed3c.jpg 360w,https://coyotle.ru/posts/pixelmuse-controlnet/00_hu_73e97c8a8d3e67f1.jpg 480w,https://coyotle.ru/posts/pixelmuse-controlnet/00_hu_3ba3a509da2e27e1.jpg 720w,https://coyotle.ru/posts/pixelmuse-controlnet/00_hu_cfbc7b5f1eb11af0.jpg 1080w,https://coyotle.ru/posts/pixelmuse-controlnet/00_hu_1a78b354950c1403.jpg 1500w,https://coyotle.ru/posts/pixelmuse-controlnet/00.jpg 2048w' src=https://coyotle.ru/posts/pixelmuse-controlnet/00.jpg sizes="(min-width: 768px) 720px, 100vw" width=2048 height=1024 alt></figure><div class=post-content><p>Добавил новую функцию для telegram-бота <a href=https://t.me/pixelmuse_bot>@pixelmuse_bot</a>. Теперь на вход ему можно отправить кривой рисунок с командой в описании <code>/imagine2 текст запроса</code> и на выходе получить что-то осмысленное и даже красивое.</p><p>Как это работает под капотом. Никакой магии, для управления нейросетью используем <a href=https://huggingface.co/docs/diffusers/main/en/api/pipelines/controlnet_sdxl>controlnet</a>. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.</p><p>После получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества.</p><p>Для теста нарисовал такой рисунок:
<img loading=lazy src=/posts/pixelmuse-controlnet/01.jpg></p><p>Загружаем исходное изображенние с помощью PIL, кропаем и ресайзим до нужного размера:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>crop</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>image</span><span class=o>.</span><span class=n>resize</span><span class=p>((</span><span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>))</span>
</span></span></code></pre></div><p>Используем cv2.Canny для создания маски с краями объектов:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>Canny</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=mi>55</span><span class=p>,</span> <span class=mi>70</span><span class=p>)</span> <span class=c1># эти параметры надо продобрать под ваши изображения</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>image</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>concatenate</span><span class=p>([</span><span class=n>image</span><span class=p>,</span> <span class=n>image</span><span class=p>,</span> <span class=n>image</span><span class=p>],</span> <span class=n>axis</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>canny_image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>fromarray</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span></code></pre></div><p>Получаем что-то такое:
<img loading=lazy src=/posts/pixelmuse-controlnet/02.jpg></p><p>В этом проекте я загружаю одну SDXL модель и переиспользую ее для разных задач и комбинаций с LoRa.
Загрузка базовой модели происходит из файла safetensors примерно так:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>vae</span> <span class=o>=</span> <span class=n>AutoencoderKL</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;madebyollin/sdxl-vae-fp16-fix&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>controlnet</span> <span class=o>=</span> <span class=n>ControlNetModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;diffusers/controlnet-canny-sdxl-1.0&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pipe</span> <span class=o>=</span> <span class=n>StableDiffusionXLPipeline</span><span class=o>.</span><span class=n>from_single_file</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>model_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>custom_pipeline</span><span class=o>=</span><span class=s2>&#34;lpw_stable_diffusion&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>max_embeddings_multiples</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>vae</span><span class=o>=</span><span class=n>vae</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>use_safetensors</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>variant</span><span class=o>=</span><span class=s2>&#34;fp16&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pipe</span><span class=o>.</span><span class=n>enable_vae_tiling</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>pipe</span><span class=o>.</span><span class=n>enable_xformers_memory_efficient_attention</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>pipe</span><span class=o>.</span><span class=n>scheduler</span> <span class=o>=</span> <span class=n>DPMSolverMultistepScheduler</span><span class=o>.</span><span class=n>from_config</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>pipe</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>config</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>use_karras_sigmas</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></div><p>Затем инициализируем <code>StableDiffusionXLControlNetPipeline</code> с помощью уже загруженной модели и controlnet:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pipe_ctrlnet</span> <span class=o>=</span> <span class=n>StableDiffusionXLControlNetPipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=n>pipe</span><span class=o>.</span><span class=n>components</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>    <span class=n>controlnet</span><span class=o>=</span><span class=n>controlnet</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>И генерим изображение:</p><pre tabindex=0><code>images = pipe_ctrlnet(
    prompt=prompt,
    negative_prompt=negative_prompt, 
    image=canny_image, 
    num_inference_steps=20, 
    controlnet_conditioning_scale=0.5,
    guidance_scale=guidance_scale).images
</code></pre><p>Результат на выходе:
<img loading=lazy src=/posts/pixelmuse-controlnet/res01.png></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://coyotle.ru/tags/%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B8/>Нейросети</a></li><li><a href=https://coyotle.ru/tags/stable-diffusion/>Stable Diffusion</a></li><li><a href=https://coyotle.ru/tags/midjourney/>Midjourney</a></li><li><a href=https://coyotle.ru/tags/%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%BE/>Искусство</a></li></ul><nav class=paginav><a class=prev href=https://coyotle.ru/posts/90s-v2-lora/><span class=title>« Предыдущая</span><br><span>Погружение в 90е</span>
</a><a class=next href=https://coyotle.ru/posts/pixel-muse/><span class=title>Следующая »</span><br><span>Telegram-бот для создания изображений нейросетью</span></a></nav></footer><div class=comments></div><script>function setComments(e){let t=document.createElement("script");t.src="https://utteranc.es/client.js",t.setAttribute("id","comments-script"),t.setAttribute("repo","coyotle/blog"),t.setAttribute("issue-term","pathname"),t.setAttribute("theme",e),t.setAttribute("label","comment"),t.setAttribute("crossorigin","anonymous"),t.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(t)}document.getElementById("theme-toggle").addEventListener("click",()=>{setComments(document.body.className.includes("dark")?"github-light":"github-dark")});let theme=document.body.className.includes("dark")?"github-dark":"github-light";setComments(theme)</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://coyotle.ru/>Мини-блог об IT, Linux, Open Source, Tech</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="копировать";function s(){t.innerHTML="скопировано!",setTimeout(()=>{t.innerHTML="копировать"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>