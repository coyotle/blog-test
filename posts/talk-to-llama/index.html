<!doctype html><html lang=ru dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Как поговорить с LLaMA голосом | Мини-блог об IT, Linux, Open Source, Tech</title><meta name=keywords content="llama,нейросети"><meta name=description content="Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.
Для общения нам понадобятся:

whisper.cpp - преобразование голоса в текст
silero - синтез речи
модель совместимая с llama.cpp

Silero TTS
По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво.
Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri."><meta name=author content><link rel=canonical href=https://coyotle.ru/posts/talk-to-llama/><link crossorigin=anonymous href=/assets/css/stylesheet.d6626ca70f3a7dda16dfce9eb29df152c81185d6739a741054093fb92b9e6839.css integrity="sha256-1mJspw86fdoW386esp3xUsgRhdZzmnQQVAk/uSueaDk=" rel="preload stylesheet" as=style><link rel=icon href=https://coyotle.ru/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://coyotle.ru/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://coyotle.ru/favicon-32x32.png><link rel=apple-touch-icon href=https://coyotle.ru/apple-touch-icon.png><link rel=mask-icon href=https://coyotle.ru/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ru href=https://coyotle.ru/posts/talk-to-llama/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://coyotle.ru/posts/talk-to-llama/"><meta property="og:site_name" content="Мини-блог об IT, Linux, Open Source, Tech"><meta property="og:title" content="Как поговорить с LLaMA голосом"><meta property="og:description" content="Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.
Для общения нам понадобятся:
whisper.cpp - преобразование голоса в текст silero - синтез речи модель совместимая с llama.cpp Silero TTS По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво. Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri."><meta property="og:locale" content="ru-RU"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-26T00:32:30+03:00"><meta property="article:modified_time" content="2023-04-26T00:32:30+03:00"><meta property="article:tag" content="Llama"><meta property="article:tag" content="Нейросети"><meta name=twitter:card content="summary"><meta name=twitter:title content="Как поговорить с LLaMA голосом"><meta name=twitter:description content="Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.
Для общения нам понадобятся:

whisper.cpp - преобразование голоса в текст
silero - синтез речи
модель совместимая с llama.cpp

Silero TTS
По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво.
Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Посты","item":"https://coyotle.ru/posts/"},{"@type":"ListItem","position":2,"name":"Как поговорить с LLaMA голосом","item":"https://coyotle.ru/posts/talk-to-llama/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Как поговорить с LLaMA голосом","name":"Как поговорить с LLaMA голосом","description":"Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.\nДля общения нам понадобятся:\nwhisper.cpp - преобразование голоса в текст silero - синтез речи модель совместимая с llama.cpp Silero TTS По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво. Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri.\n","keywords":["llama","нейросети"],"articleBody":"Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.\nДля общения нам понадобятся:\nwhisper.cpp - преобразование голоса в текст silero - синтез речи модель совместимая с llama.cpp Silero TTS По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво. Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri.\nmkdir tts-silero cd tts-silero python -m venv venv/bin/activate pip install torch torchaudio playsound omegaconf На основе Jupyter плейбука cоздаём скрипт tts.py:\nimport sys import torch import torchaudio from pprint import pprint from omegaconf import OmegaConf from IPython.display import Audio, display from playsound import playsound torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml', 'latest_silero_models.yml', progress=False) models = OmegaConf.load('latest_silero_models.yml') language = 'en' model_id = 'v3_en' device = torch.device('cpu') # gpu or cpu model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models', model='silero_tts', language=language, speaker=model_id) model.to(device) sample_rate = 48000 speaker = 'en_21' # voice put_accent=True put_yo=True text_to_speach = sys.argv[1] print(text_to_speach) audio = model.apply_tts(text=text_to_speach, speaker=speaker, sample_rate=sample_rate, put_accent=put_accent, put_yo=put_yo) torchaudio.save('out.mp3', audio.unsqueeze(0), sample_rate=sample_rate) playsound('out.mp3') Сэмплы английских голосов можно послушать тут.\nПроверяем работу скрипта:\nvenv/bin/python tts.py \"Hello! How are you?\" Если услышали приятный женский голос - значит все получилось и можно идти дальше.\nWhisper.cpp + llama.cpp Whisper.cpp - крутой проект автоматического распознаванием голоса, в том числе умеет real-time распознавание.\nКлонируем код:\ngit clone https://github.com/ggerganov/whisper.cpp.git Собираем talk-llama:\ncd whisper.cpp make talk-llama Скачиваем модель для распознавания голоса:\nmodels/download-ggml-model.sh base В каталоге models должен появиться файл ggml-base.bin.\nПравим examples/talk-llama/speak.sh:\n#!/bin/bash # Usage: # speak.sh # для пользователей Mac #say \"$2\" ../tts-silero/venv/bin/python ../tts-silero/tts.py \"$2\" #\u003e /dev/null 2\u003e\u00261 Попробуем запустить:\n./talk-llama -t 8 -tr --person Sergey -mw models/ggml-base.bin -ml ../llama.cpp/models/vicuna-13b-ggml-4bit.bin --prompt-file examples/talk-llama/prompts/talk-alpaca.txt -t - количество потоков\n-tr - (необязательно) перевод любого языка на английский перед передачей текста в llama модель. Переводит не очень хорошо, но это единственный способ обратиться к модели на русском.\n-l LANG - (необязательно) теоретически можно указать язык ru. Whysper.cpp отлично работает с русским, но в случае с talk-llama похоже что-то с кодировкой и вместо русского остаются только знаки препинания. --person - (необязательно) ваше имя\n-mw - путь к STT модели\n-ml - путь к llama модели --prompt-file - (необязательно) путь к начальному промпту, можно описать персонажа для чат-бота.\nПодождите инициализации моделей и появления приглашения с вашим именем. После этого можно говорить с моделью и получать ответ голосом.\nМог пропустить какие-то шаги по установке зависимостей, думаю вы увидите если не хватает каких-то библиотек, доустановите их.\nЕсли кто-то знает как заставить talk-llama работать с русским - пишите в комментариях.\n","wordCount":"419","inLanguage":"ru","datePublished":"2023-04-26T00:32:30+03:00","dateModified":"2023-04-26T00:32:30+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://coyotle.ru/posts/talk-to-llama/"},"publisher":{"@type":"Organization","name":"Мини-блог об IT, Linux, Open Source, Tech","logo":{"@type":"ImageObject","url":"https://coyotle.ru/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://coyotle.ru/ accesskey=h title="Мини-блог об IT, Linux, Open Source, Tech (Alt + H)">Мини-блог об IT, Linux, Open Source, Tech</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://coyotle.ru/tags/ title=тэги><span>тэги</span></a></li><li><a href=https://coyotle.ru/about/ title="обо мне"><span>обо мне</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Как поговорить с LLaMA голосом</h1><div class=post-meta><span title='2023-04-26 00:32:30 +0300 +0300'>26 апреля 2023</span></div></header><div class=post-content><p>Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.</p><p>Для общения нам понадобятся:</p><ul><li><strong>whisper.cpp</strong> - преобразование голоса в текст</li><li><strong>silero</strong> - синтез речи</li><li>модель совместимая с <strong>llama.cpp</strong></li></ul><h3 id=silero-tts>Silero TTS<a hidden class=anchor aria-hidden=true href=#silero-tts>#</a></h3><p>По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво.
Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>mkdir tts-silero
</span></span><span class=line><span class=cl><span class=nb>cd</span> tts-silero
</span></span><span class=line><span class=cl>python -m venv
</span></span><span class=line><span class=cl>venv/bin/activate
</span></span><span class=line><span class=cl>pip install torch torchaudio playsound omegaconf
</span></span></code></pre></div><p>На основе <a href=https://github.com/snakers4/silero-models/blob/master/examples_tts.ipynb>Jupyter плейбука</a> cоздаём скрипт tts.py:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>sys</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchaudio</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pprint</span> <span class=kn>import</span> <span class=n>pprint</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>OmegaConf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>Audio</span><span class=p>,</span> <span class=n>display</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>playsound</span> <span class=kn>import</span> <span class=n>playsound</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>hub</span><span class=o>.</span><span class=n>download_url_to_file</span><span class=p>(</span><span class=s1>&#39;https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                               <span class=s1>&#39;latest_silero_models.yml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                               <span class=n>progress</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>models</span> <span class=o>=</span> <span class=n>OmegaConf</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;latest_silero_models.yml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>language</span> <span class=o>=</span> <span class=s1>&#39;en&#39;</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s1>&#39;v3_en&#39;</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cpu&#39;</span><span class=p>)</span> <span class=c1># gpu or cpu</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>example_text</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>hub</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>repo_or_dir</span><span class=o>=</span><span class=s1>&#39;snakers4/silero-models&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                     <span class=n>model</span><span class=o>=</span><span class=s1>&#39;silero_tts&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                     <span class=n>language</span><span class=o>=</span><span class=n>language</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                     <span class=n>speaker</span><span class=o>=</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>  
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sample_rate</span> <span class=o>=</span> <span class=mi>48000</span>
</span></span><span class=line><span class=cl><span class=n>speaker</span> <span class=o>=</span> <span class=s1>&#39;en_21&#39;</span> <span class=c1># voice</span>
</span></span><span class=line><span class=cl><span class=n>put_accent</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=n>put_yo</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text_to_speach</span> <span class=o>=</span> <span class=n>sys</span><span class=o>.</span><span class=n>argv</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>text_to_speach</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>audio</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>apply_tts</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text_to_speach</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>speaker</span><span class=o>=</span><span class=n>speaker</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>sample_rate</span><span class=o>=</span><span class=n>sample_rate</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>put_accent</span><span class=o>=</span><span class=n>put_accent</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>put_yo</span><span class=o>=</span><span class=n>put_yo</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>torchaudio</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s1>&#39;out.mp3&#39;</span><span class=p>,</span> <span class=n>audio</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span> <span class=n>sample_rate</span><span class=o>=</span><span class=n>sample_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>playsound</span><span class=p>(</span><span class=s1>&#39;out.mp3&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>Сэмплы английских голосов можно послушать <a href=https://oobabooga.github.io/silero-samples/index.html>тут</a>.</p><p>Проверяем работу скрипта:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>venv/bin/python tts.py <span class=s2>&#34;Hello! How are you?&#34;</span>
</span></span></code></pre></div><p>Если услышали приятный женский голос - значит все получилось и можно идти дальше.</p><h3 id=whispercpp--llamacpp>Whisper.cpp + llama.cpp<a hidden class=anchor aria-hidden=true href=#whispercpp--llamacpp>#</a></h3><p>Whisper.cpp - крутой проект автоматического распознаванием голоса, в том числе умеет real-time распознавание.</p><p>Клонируем код:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>git clone https://github.com/ggerganov/whisper.cpp.git
</span></span></code></pre></div><p>Собираем talk-llama:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=nb>cd</span> whisper.cpp
</span></span><span class=line><span class=cl>make talk-llama
</span></span></code></pre></div><p>Скачиваем модель для распознавания голоса:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>models/download-ggml-model.sh base
</span></span></code></pre></div><p>В каталоге <code>models</code> должен появиться файл <code>ggml-base.bin</code>.</p><p>Правим <code>examples/talk-llama/speak.sh</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=cp>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=c1># Usage:</span>
</span></span><span class=line><span class=cl><span class=c1>#  speak.sh &lt;voice_id&gt; &lt;text-to-speak&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># для пользователей Mac</span>
</span></span><span class=line><span class=cl><span class=c1>#say &#34;$2&#34;</span>
</span></span><span class=line><span class=cl>../tts-silero/venv/bin/python ../tts-silero/tts.py <span class=s2>&#34;</span><span class=nv>$2</span><span class=s2>&#34;</span> <span class=c1>#&gt; /dev/null 2&gt;&amp;1</span>
</span></span></code></pre></div><p>Попробуем запустить:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>./talk-llama -t <span class=m>8</span> -tr --person Sergey -mw models/ggml-base.bin -ml ../llama.cpp/models/vicuna-13b-ggml-4bit.bin --prompt-file examples/talk-llama/prompts/talk-alpaca.txt
</span></span></code></pre></div><p><code>-t</code> - количество потоков<br><code>-tr</code> - (необязательно) перевод любого языка на английский перед передачей текста в llama модель. Переводит не очень хорошо, но это единственный способ обратиться к модели на русском.<br><code>-l LANG</code> - (необязательно) теоретически можно указать язык <code>ru</code>. Whysper.cpp отлично работает с русским, но в случае с talk-llama похоже что-то с кодировкой и вместо русского остаются только знаки препинания.<br><code>--person </code>- (необязательно) ваше имя<br><code>-mw</code> - путь к STT модели<br><code>-ml</code> - путь к llama модели<br><code>--prompt-file</code> - (необязательно) путь к начальному промпту, можно описать персонажа для чат-бота.</p><p>Подождите инициализации моделей и появления приглашения с вашим именем. После этого можно говорить с моделью и получать ответ голосом.</p><p>Мог пропустить какие-то шаги по установке зависимостей, думаю вы увидите если не хватает каких-то библиотек, доустановите их.</p><p>Если кто-то знает как заставить talk-llama работать с русским - пишите в комментариях.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://coyotle.ru/tags/llama/>Llama</a></li><li><a href=https://coyotle.ru/tags/%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B8/>Нейросети</a></li></ul><nav class=paginav><a class=prev href=https://coyotle.ru/posts/chatgpt-at-home/><span class=title>« Предыдущая</span><br><span>У нас есть ChatGPT дома</span>
</a><a class=next href=https://coyotle.ru/posts/ai-and-ethic/><span class=title>Следующая »</span><br><span>Этика ИИ. Корпорации врут, а мы катимся в пропасть?</span></a></nav></footer><div class=comments></div><script>function setComments(e){let t=document.createElement("script");t.src="https://utteranc.es/client.js",t.setAttribute("id","comments-script"),t.setAttribute("repo","coyotle/blog"),t.setAttribute("issue-term","pathname"),t.setAttribute("theme",e),t.setAttribute("label","comment"),t.setAttribute("crossorigin","anonymous"),t.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(t)}document.getElementById("theme-toggle").addEventListener("click",()=>{setComments(document.body.className.includes("dark")?"github-light":"github-dark")});let theme=document.body.className.includes("dark")?"github-dark":"github-light";setComments(theme)</script></article></main><footer class=footer><span>&copy; 2025 <a href=https://coyotle.ru/>Мини-блог об IT, Linux, Open Source, Tech</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="копировать";function s(){t.innerHTML="скопировано!",setTimeout(()=>{t.innerHTML="копировать"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>