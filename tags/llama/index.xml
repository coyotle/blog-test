<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Llama on Мини-блог об IT, Linux, Open Source, Tech</title><link>https://coyotle.ru/tags/llama/</link><description>Recent content in Llama on Мини-блог об IT, Linux, Open Source, Tech</description><generator>Hugo -- 0.152.2</generator><language>ru-RU</language><lastBuildDate>Sun, 23 Mar 2025 23:37:24 +0300</lastBuildDate><atom:link href="https://coyotle.ru/tags/llama/index.xml" rel="self" type="application/rss+xml"/><item><title>Как обучить языковую модель самостоятельно</title><link>https://coyotle.ru/posts/tarot-bot-p1/</link><pubDate>Sun, 23 Mar 2025 23:37:24 +0300</pubDate><guid>https://coyotle.ru/posts/tarot-bot-p1/</guid><description>&lt;p&gt;Мне не давал покоя вопрос, можно ли на моей нищенской RTX3060 12Gb натренировать свою (не)большую языковую модель. И как оказалось - да, это сделать можно используя Low-Rank Adaptation (LoRA). Т.к. VRAM немного, 8B - это самая большая модель из семейства лама которую можно натренировать на этой карте. Что для этого надо?&lt;/p&gt;
&lt;h2 id="1-грабим-данные"&gt;1. Грабим данные&lt;/h2&gt;
&lt;p&gt;У меня была идея сделать модель которая будет помогать с трактовкой карт Таро, поэтому идем и грабим &lt;del&gt;корованы&lt;/del&gt; сайты с описанием карт и раскладов таро. Для ограбления я написал небольшой python скрипт и с использованием beautifulsoup4 сохранил результат в отдельные JSON файлы.&lt;/p&gt;</description></item><item><title>Shell доступ к хосту через LLM и мини-игра</title><link>https://coyotle.ru/posts/llm-shell/</link><pubDate>Fri, 09 Aug 2024 23:10:56 +0300</pubDate><guid>https://coyotle.ru/posts/llm-shell/</guid><description>&lt;p&gt;Разбираясь с &lt;a href="https://ollama.com/"&gt;ollama&lt;/a&gt; и моделью &lt;a href="https://ollama.com/library/llama3.1"&gt;llama3.1&lt;/a&gt; увидел в документации, что ollama для некоторых моделей поддерживает вызов функций. Если коротко - модели под капотом передается JSON описывающий набор функций доступных ей для выполнения. Так можно добавить модели функцию получения информации из внешних источников или взаимодействия с какими-то системами. В документации приводят функцию получения текущей погоды для указанного города:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-json" data-lang="json"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;function&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;function&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;get_current_weather&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;description&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;Get the current weather for a city&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;parameters&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;object&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;properties&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;city&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;string&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;description&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;#34;The name of the city&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nt"&gt;&amp;#34;required&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;#34;city&amp;#34;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="p"&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Простой код для использования функции будет примерно таким:&lt;/p&gt;</description></item><item><title>У нас есть ChatGPT дома</title><link>https://coyotle.ru/posts/chatgpt-at-home/</link><pubDate>Thu, 27 Apr 2023 09:45:03 +0300</pubDate><guid>https://coyotle.ru/posts/chatgpt-at-home/</guid><description>&lt;p&gt;В статье опишу настройку web API и web-чат похожего на ChatGPT для LLaMA-подобных моделей. Всё это довольно сносно работает на CPU Ryzen 3600 + 32ГБ ОЗУ.&lt;/p&gt;
&lt;h2 id="api--веб-чат"&gt;API + веб чат&lt;/h2&gt;
&lt;p&gt;Для настройки нам понадобятся три проекта:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;llama.cpp&lt;/strong&gt; - мозг нашей системы&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gpt-llama.cpp&lt;/strong&gt; - эмулирует API от OpenAI. Реализовано не всё&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;chatbot-ui&lt;/strong&gt; - web интерфейс для доступа к моделям OpenAI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;После установки компонентов должна получиться такая структура:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-sh" data-lang="sh"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;local-chat - корень проекта
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;├── chatbot-ui
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;├── gpt-llama.cpp
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;└── llama.cpp
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;    ├── main*
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;    └── models/your-ggml-model.bin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="llamacpp"&gt;llama.cpp&lt;/h3&gt;
&lt;p&gt;Думаю многие уже попробовали установить и пообщаться с llama-подобными моделями, но в любом случае опишу процесс установки.&lt;/p&gt;</description></item><item><title>Как поговорить с LLaMA голосом</title><link>https://coyotle.ru/posts/talk-to-llama/</link><pubDate>Wed, 26 Apr 2023 00:32:30 +0300</pubDate><guid>https://coyotle.ru/posts/talk-to-llama/</guid><description>&lt;p&gt;Наверное уже все пообщались в текстовом режиме с llama-подобными моделями, в этой заметке расскажу как можно настроить полностью голосовое общение с моделью.&lt;/p&gt;
&lt;p&gt;Для общения нам понадобятся:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;whisper.cpp&lt;/strong&gt; - преобразование голоса в текст&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;silero&lt;/strong&gt; - синтез речи&lt;/li&gt;
&lt;li&gt;модель совместимая с &lt;strong&gt;llama.cpp&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="silero-tts"&gt;Silero TTS&lt;/h3&gt;
&lt;p&gt;По моему Silero лучший синтезатор речи который можно запустить под Linux с довольно приличной скорость на CPU. На хабре есть несколько статей от разработчиков, поищите, интересное чтиво.
Пользователи Mac могу пропустить этот шаг и использовать для синтеза Siri.&lt;/p&gt;</description></item></channel></rss>