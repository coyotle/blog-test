<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Stable Diffusion on Мини-блог об IT, Linux, Open Source, Tech</title><link>https://coyotle.ru/tags/stable-diffusion/</link><description>Recent content in Stable Diffusion on Мини-блог об IT, Linux, Open Source, Tech</description><generator>Hugo -- 0.152.2</generator><language>ru-RU</language><lastBuildDate>Mon, 05 May 2025 10:21:45 +0300</lastBuildDate><atom:link href="https://coyotle.ru/tags/stable-diffusion/index.xml" rel="self" type="application/rss+xml"/><item><title>Погружение в 90е (SDXL версия)</title><link>https://coyotle.ru/posts/90s-xl-lora/</link><pubDate>Mon, 05 May 2025 10:21:45 +0300</pubDate><guid>https://coyotle.ru/posts/90s-xl-lora/</guid><description>&lt;p&gt;Натренировал новую SDXL версию своей лоры под стиль аналоговых фото 90-х. LoRa добавляет тени от вспышки, утечки света, цвета в стиле ломо.&lt;/p&gt;
&lt;p&gt;Для SDXL версии пришлось пересобрать датасет, исправить описания и неделю поэксперементировать с параметрами.&lt;/p&gt;
&lt;p&gt;&lt;img loading="lazy" src="https://coyotle.ru/posts/90s-xl-lora/lora_xl.png"&gt;&lt;/p&gt;
&lt;p&gt;Скачать для экспериментов можно на &lt;a href="https://huggingface.co/coyotle/90s_flash_photo"&gt;HuggingFace&lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Как запустить Flux с помощью ComfyUI на 12ГБ VRAM</title><link>https://coyotle.ru/posts/flux-setup/</link><pubDate>Mon, 05 Aug 2024 00:45:04 +0300</pubDate><guid>https://coyotle.ru/posts/flux-setup/</guid><description>&lt;p&gt;В инфополе ворвалась новая диффузионная модель Flux и порвала всех конкурентов.
Из своих тестов и того, что видел на Reddit, изображения значительно лучше, особенно в плане анатомии и злосчастных рук, чем то, что делает Stable Diffusion.
Модель доступна в двух вариантах Schnell (разрешено использование в коммерческих проектах) и Dev (не для коммерческого использования). Обе версии имеют один размер, но Schnell генерирует изображения за меньшее число шагов и немного худшего качества чем Dev.
Модели значительно больше по размеру чем SDXL и новая (неудачная) SD3, и весят почти 24ГБ.&lt;/p&gt;</description></item><item><title>Погружение в 90е</title><link>https://coyotle.ru/posts/90s-v2-lora/</link><pubDate>Sun, 05 Nov 2023 17:21:45 +0300</pubDate><guid>https://coyotle.ru/posts/90s-v2-lora/</guid><description>&lt;p&gt;Для ностальгирующих по эстетике 90х.
После пары недель экспериментов с kohya_ss и подробом параметров зарелизил вторую версию LoRa для создания картинок в стиле фотографий на мыльницы со вспышкой.
Скачать для экспериментов можно на &lt;a href="https://civitai.com/models/84662"&gt;Civitai&lt;/a&gt;.
&lt;img loading="lazy" src="https://coyotle.ru/posts/90s-v2-lora/90s_v2.png"&gt;
По сравнению с первой версией эту лору можно использовать с большей strength не ломая изображение.
В последний заход потратил часов восемь на тренировку и около 80 эпох. По факту оказалось, что после 5-6 эпох LoRa уже сильно перетренирована, хотя Loss так и не достиг минимума и продолжал уменьшаться.&lt;/p&gt;</description></item><item><title>Controlnet для тг-бота pixelmuse</title><link>https://coyotle.ru/posts/pixelmuse-controlnet/</link><pubDate>Tue, 17 Oct 2023 20:21:45 +0300</pubDate><guid>https://coyotle.ru/posts/pixelmuse-controlnet/</guid><description>&lt;p&gt;Добавил новую функцию для telegram-бота &lt;a href="https://t.me/pixelmuse_bot"&gt;@pixelmuse_bot&lt;/a&gt;. Теперь на вход ему можно отправить кривой рисунок с командой в описании &lt;code&gt;/imagine2 текст запроса&lt;/code&gt; и на выходе получить что-то осмысленное и даже красивое.&lt;/p&gt;
&lt;p&gt;Как это работает под капотом. Никакой магии, для управления нейросетью используем &lt;a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/controlnet_sdxl"&gt;controlnet&lt;/a&gt;. Controlnet заставляет нейросеть использовать информацию о границах объектов как опору для создания нового изображения.&lt;/p&gt;
&lt;p&gt;После получения изображения от пользователя обрабатываем его с помощью cv2.Canny для определения краев. Тут пришлось поэксперементировать с параметрами чтобы края определялись в том числе на фотографиях, где переходы, например на лице, могут быть плавными, а потеря этих границ даёт модели слишком много свободы для творчества.&lt;/p&gt;</description></item><item><title>Telegram-бот для создания изображений нейросетью</title><link>https://coyotle.ru/posts/pixel-muse/</link><pubDate>Fri, 22 Sep 2023 17:21:45 +0300</pubDate><guid>https://coyotle.ru/posts/pixel-muse/</guid><description>&lt;p&gt;В общем, кому не хватало Midjourney у нас дома - добро пожаловать в &lt;a href="https://t.me/pixelmuse_bot"&gt;@pixelmuse_bot&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Что бот умеет на данный момент:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Создавать картинки по текстовому запросу&lt;/li&gt;
&lt;li&gt;Используется автоматический машинный перевод текста на английский, поэтому запрос может быть практически на любом языке&lt;/li&gt;
&lt;li&gt;Можно выбрать из 5 моделей: реализм, аниме, киборги, sci-fi окружение, стикеры (по факту под капотом две модели + разные LoRa)&lt;/li&gt;
&lt;li&gt;Можно загрузить свою фотографию для обработки img2img&lt;/li&gt;
&lt;li&gt;Можно сделать апскейл результата x1.5. Для апскейла используется нейронка Real-ESRGAN&lt;/li&gt;
&lt;li&gt;Даю 20 токенов для тестов (20 изображений) с лимитом 10 токенов в день&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dev-лог"&gt;Dev-лог&lt;/h2&gt;
&lt;p&gt;Какое-то время ковырял Stable Diffusion в Автоматик111 и ComfyUI. В один &lt;del&gt;прекрасный&lt;/del&gt; депрессивный день решил посмотреть, как работать с сетью напрямую в python. Сделать это можно с помощью библиотеке diffusers от Hugging Face. Написал пятистрочный скрипт и подумал почему бы ради прикола не приделать к нему телеграм бота, и тут понеслось.&lt;/p&gt;</description></item><item><title>Искусство и Stable Diffusion</title><link>https://coyotle.ru/posts/stable-diffusion/</link><pubDate>Fri, 07 Oct 2022 23:53:56 +0300</pubDate><guid>https://coyotle.ru/posts/stable-diffusion/</guid><description>&lt;p&gt;Поэксперементировал с генерацией изображений нейросетью Stable Diffusion. Сеть умеет text-to-image - создавать изображения по текстовому описанию. Очень забавно. Выше мои попытки &amp;ldquo;нарисовать&amp;rdquo; что-то. Попробовать и посмотреть творчество других людей можно тут &lt;a href="https://www.mage.space/"&gt;https://www.mage.space/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="stable.webp"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Сначала хотел написать, что нейросеть это не искусство, что это просто результат сложного бросания кубиков. Кроме того, сеть обучена на большом количестве фото, картин и рисунков разных авторов без их разрешения.
С другой стороны, живые люди так же учатся глядя на картины, смотря фильмы, постановки которые были созданы кем-то другим, вдохновляются этим, подсматривают идеи и приёмы.&lt;/p&gt;</description></item></channel></rss>