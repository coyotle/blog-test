<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Llam on Мини-блог об IT, Linux, Open Source, Tech</title><link>https://coyotle.ru/tags/llam/</link><description>Recent content in Llam on Мини-блог об IT, Linux, Open Source, Tech</description><generator>Hugo -- 0.152.2</generator><language>ru-RU</language><lastBuildDate>Wed, 01 May 2024 15:06:04 +0300</lastBuildDate><atom:link href="https://coyotle.ru/tags/llam/index.xml" rel="self" type="application/rss+xml"/><item><title>Простой llama-3 телеграм бот</title><link>https://coyotle.ru/posts/simple-ai-bot/</link><pubDate>Wed, 01 May 2024 15:06:04 +0300</pubDate><guid>https://coyotle.ru/posts/simple-ai-bot/</guid><description>&lt;p&gt;В заметке расскажу как на python сделать простого чат бота для телеграм на базе последней версии llm модели llama-3.&lt;/p&gt;
&lt;p&gt;Предположим у нас уже установлен python и CUDA (если хотите использовать gpu для ускорения).
Для взаимодействия с моделью на python есть несколько вариантов, чтобы не усложнять будем использовать библиотеку llama.cpp и квантованную модель в формате GGUF. Обратите внимание, нужна Instruct версия.&lt;/p&gt;
&lt;h2 id="подготовка"&gt;Подготовка&lt;/h2&gt;
&lt;p&gt;В телеграм с помощью &lt;code&gt;@BotFather&lt;/code&gt; создайте нового бота и получите токен.&lt;/p&gt;</description></item></channel></rss>