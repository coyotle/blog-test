<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Pytorch on Мини-блог об IT, Linux, Open Source, Tech</title><link>https://coyotle.ru/tags/pytorch/</link><description>Recent content in Pytorch on Мини-блог об IT, Linux, Open Source, Tech</description><generator>Hugo -- 0.152.2</generator><language>ru-RU</language><lastBuildDate>Sat, 11 Feb 2023 23:34:29 +0300</lastBuildDate><atom:link href="https://coyotle.ru/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>Подготовка данных для нейронной сети</title><link>https://coyotle.ru/posts/ml-preparing-data/</link><pubDate>Sat, 11 Feb 2023 23:34:29 +0300</pubDate><guid>https://coyotle.ru/posts/ml-preparing-data/</guid><description>&lt;p&gt;На волне шумихи вокруг GPT-3 появилось желание покапаться во внутреннем устройстве нейронных сетей и попробовать написать сеть для классификации текстов по категориям/тэгам. Это первая заметка из серии, речь в ней пойдет о предварительной подготовке данных.&lt;/p&gt;
&lt;p&gt;Зачем необходима подготовка данных? Текстовые данные не могут быть использованы напрямую в моделях машинного обучения, так как в нейронах используются простые математические функции которые работают с числовыми данными. Для подготовки текстовых данных используют так называемое кодирование слов - это преобразование текстовых данных в числовые (векторные) представления, которые затем можно использовать для машинного обучения.
&lt;img loading="lazy" src="https://coyotle.ru/posts/ml-preparing-data/leo_and_ml.png"&gt;
Существует много способов кодирования, вот некоторые из них:&lt;/p&gt;</description></item></channel></rss>